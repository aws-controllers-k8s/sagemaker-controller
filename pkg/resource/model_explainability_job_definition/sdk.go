// Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License"). You may
// not use this file except in compliance with the License. A copy of the
// License is located at
//
//     http://aws.amazon.com/apache2.0/
//
// or in the "license" file accompanying this file. This file is distributed
// on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
// express or implied. See the License for the specific language governing
// permissions and limitations under the License.

// Code generated by ack-generate. DO NOT EDIT.

package model_explainability_job_definition

import (
	"context"
	"errors"
	"fmt"
	"math"
	"reflect"
	"strings"

	ackv1alpha1 "github.com/aws-controllers-k8s/runtime/apis/core/v1alpha1"
	ackcompare "github.com/aws-controllers-k8s/runtime/pkg/compare"
	ackcondition "github.com/aws-controllers-k8s/runtime/pkg/condition"
	ackerr "github.com/aws-controllers-k8s/runtime/pkg/errors"
	ackrequeue "github.com/aws-controllers-k8s/runtime/pkg/requeue"
	ackrtlog "github.com/aws-controllers-k8s/runtime/pkg/runtime/log"
	"github.com/aws/aws-sdk-go-v2/aws"
	svcsdk "github.com/aws/aws-sdk-go-v2/service/sagemaker"
	svcsdktypes "github.com/aws/aws-sdk-go-v2/service/sagemaker/types"
	smithy "github.com/aws/smithy-go"
	corev1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"

	svcapitypes "github.com/aws-controllers-k8s/sagemaker-controller/apis/v1alpha1"
)

// Hack to avoid import errors during build...
var (
	_ = &metav1.Time{}
	_ = strings.ToLower("")
	_ = &svcsdk.Client{}
	_ = &svcapitypes.ModelExplainabilityJobDefinition{}
	_ = ackv1alpha1.AWSAccountID("")
	_ = &ackerr.NotFound
	_ = &ackcondition.NotManagedMessage
	_ = &reflect.Value{}
	_ = fmt.Sprintf("")
	_ = &ackrequeue.NoRequeue{}
	_ = &aws.Config{}
)

// sdkFind returns SDK-specific information about a supplied resource
func (rm *resourceManager) sdkFind(
	ctx context.Context,
	r *resource,
) (latest *resource, err error) {
	rlog := ackrtlog.FromContext(ctx)
	exit := rlog.Trace("rm.sdkFind")
	defer func() {
		exit(err)
	}()
	// If any required fields in the input shape are missing, AWS resource is
	// not created yet. Return NotFound here to indicate to callers that the
	// resource isn't yet created.
	if rm.requiredFieldsMissingFromReadOneInput(r) {
		return nil, ackerr.NotFound
	}

	input, err := rm.newDescribeRequestPayload(r)
	if err != nil {
		return nil, err
	}

	var resp *svcsdk.DescribeModelExplainabilityJobDefinitionOutput
	resp, err = rm.sdkapi.DescribeModelExplainabilityJobDefinition(ctx, input)
	rm.metrics.RecordAPICall("READ_ONE", "DescribeModelExplainabilityJobDefinition", err)
	if err != nil {
		var awsErr smithy.APIError
		if errors.As(err, &awsErr) && awsErr.ErrorCode() == "ResourceNotFound" {
			return nil, ackerr.NotFound
		}
		return nil, err
	}

	// Merge in the information we read from the API call above to the copy of
	// the original Kubernetes object we passed to the function
	ko := r.ko.DeepCopy()

	if ko.Status.ACKResourceMetadata == nil {
		ko.Status.ACKResourceMetadata = &ackv1alpha1.ResourceMetadata{}
	}
	if resp.JobDefinitionArn != nil {
		arn := ackv1alpha1.AWSResourceName(*resp.JobDefinitionArn)
		ko.Status.ACKResourceMetadata.ARN = &arn
	}
	if resp.JobDefinitionName != nil {
		ko.Spec.JobDefinitionName = resp.JobDefinitionName
	} else {
		ko.Spec.JobDefinitionName = nil
	}
	if resp.JobResources != nil {
		f3 := &svcapitypes.MonitoringResources{}
		if resp.JobResources.ClusterConfig != nil {
			f3f0 := &svcapitypes.MonitoringClusterConfig{}
			if resp.JobResources.ClusterConfig.InstanceCount != nil {
				instanceCountCopy := int64(*resp.JobResources.ClusterConfig.InstanceCount)
				f3f0.InstanceCount = &instanceCountCopy
			}
			if resp.JobResources.ClusterConfig.InstanceType != "" {
				f3f0.InstanceType = aws.String(string(resp.JobResources.ClusterConfig.InstanceType))
			}
			if resp.JobResources.ClusterConfig.VolumeKmsKeyId != nil {
				f3f0.VolumeKMSKeyID = resp.JobResources.ClusterConfig.VolumeKmsKeyId
			}
			if resp.JobResources.ClusterConfig.VolumeSizeInGB != nil {
				volumeSizeInGBCopy := int64(*resp.JobResources.ClusterConfig.VolumeSizeInGB)
				f3f0.VolumeSizeInGB = &volumeSizeInGBCopy
			}
			f3.ClusterConfig = f3f0
		}
		ko.Spec.JobResources = f3
	} else {
		ko.Spec.JobResources = nil
	}
	if resp.ModelExplainabilityAppSpecification != nil {
		f4 := &svcapitypes.ModelExplainabilityAppSpecification{}
		if resp.ModelExplainabilityAppSpecification.ConfigUri != nil {
			f4.ConfigURI = resp.ModelExplainabilityAppSpecification.ConfigUri
		}
		if resp.ModelExplainabilityAppSpecification.Environment != nil {
			f4.Environment = aws.StringMap(resp.ModelExplainabilityAppSpecification.Environment)
		}
		if resp.ModelExplainabilityAppSpecification.ImageUri != nil {
			f4.ImageURI = resp.ModelExplainabilityAppSpecification.ImageUri
		}
		ko.Spec.ModelExplainabilityAppSpecification = f4
	} else {
		ko.Spec.ModelExplainabilityAppSpecification = nil
	}
	if resp.ModelExplainabilityBaselineConfig != nil {
		f5 := &svcapitypes.ModelExplainabilityBaselineConfig{}
		if resp.ModelExplainabilityBaselineConfig.BaseliningJobName != nil {
			f5.BaseliningJobName = resp.ModelExplainabilityBaselineConfig.BaseliningJobName
		}
		if resp.ModelExplainabilityBaselineConfig.ConstraintsResource != nil {
			f5f1 := &svcapitypes.MonitoringConstraintsResource{}
			if resp.ModelExplainabilityBaselineConfig.ConstraintsResource.S3Uri != nil {
				f5f1.S3URI = resp.ModelExplainabilityBaselineConfig.ConstraintsResource.S3Uri
			}
			f5.ConstraintsResource = f5f1
		}
		ko.Spec.ModelExplainabilityBaselineConfig = f5
	} else {
		ko.Spec.ModelExplainabilityBaselineConfig = nil
	}
	if resp.ModelExplainabilityJobInput != nil {
		f6 := &svcapitypes.ModelExplainabilityJobInput{}
		if resp.ModelExplainabilityJobInput.EndpointInput != nil {
			f6f0 := &svcapitypes.EndpointInput{}
			if resp.ModelExplainabilityJobInput.EndpointInput.EndTimeOffset != nil {
				f6f0.EndTimeOffset = resp.ModelExplainabilityJobInput.EndpointInput.EndTimeOffset
			}
			if resp.ModelExplainabilityJobInput.EndpointInput.EndpointName != nil {
				f6f0.EndpointName = resp.ModelExplainabilityJobInput.EndpointInput.EndpointName
			}
			if resp.ModelExplainabilityJobInput.EndpointInput.ExcludeFeaturesAttribute != nil {
				f6f0.ExcludeFeaturesAttribute = resp.ModelExplainabilityJobInput.EndpointInput.ExcludeFeaturesAttribute
			}
			if resp.ModelExplainabilityJobInput.EndpointInput.FeaturesAttribute != nil {
				f6f0.FeaturesAttribute = resp.ModelExplainabilityJobInput.EndpointInput.FeaturesAttribute
			}
			if resp.ModelExplainabilityJobInput.EndpointInput.InferenceAttribute != nil {
				f6f0.InferenceAttribute = resp.ModelExplainabilityJobInput.EndpointInput.InferenceAttribute
			}
			if resp.ModelExplainabilityJobInput.EndpointInput.LocalPath != nil {
				f6f0.LocalPath = resp.ModelExplainabilityJobInput.EndpointInput.LocalPath
			}
			if resp.ModelExplainabilityJobInput.EndpointInput.ProbabilityAttribute != nil {
				f6f0.ProbabilityAttribute = resp.ModelExplainabilityJobInput.EndpointInput.ProbabilityAttribute
			}
			if resp.ModelExplainabilityJobInput.EndpointInput.ProbabilityThresholdAttribute != nil {
				f6f0.ProbabilityThresholdAttribute = resp.ModelExplainabilityJobInput.EndpointInput.ProbabilityThresholdAttribute
			}
			if resp.ModelExplainabilityJobInput.EndpointInput.S3DataDistributionType != "" {
				f6f0.S3DataDistributionType = aws.String(string(resp.ModelExplainabilityJobInput.EndpointInput.S3DataDistributionType))
			}
			if resp.ModelExplainabilityJobInput.EndpointInput.S3InputMode != "" {
				f6f0.S3InputMode = aws.String(string(resp.ModelExplainabilityJobInput.EndpointInput.S3InputMode))
			}
			if resp.ModelExplainabilityJobInput.EndpointInput.StartTimeOffset != nil {
				f6f0.StartTimeOffset = resp.ModelExplainabilityJobInput.EndpointInput.StartTimeOffset
			}
			f6.EndpointInput = f6f0
		}
		ko.Spec.ModelExplainabilityJobInput = f6
	} else {
		ko.Spec.ModelExplainabilityJobInput = nil
	}
	if resp.ModelExplainabilityJobOutputConfig != nil {
		f7 := &svcapitypes.MonitoringOutputConfig{}
		if resp.ModelExplainabilityJobOutputConfig.KmsKeyId != nil {
			f7.KMSKeyID = resp.ModelExplainabilityJobOutputConfig.KmsKeyId
		}
		if resp.ModelExplainabilityJobOutputConfig.MonitoringOutputs != nil {
			f7f1 := []*svcapitypes.MonitoringOutput{}
			for _, f7f1iter := range resp.ModelExplainabilityJobOutputConfig.MonitoringOutputs {
				f7f1elem := &svcapitypes.MonitoringOutput{}
				if f7f1iter.S3Output != nil {
					f7f1elemf0 := &svcapitypes.MonitoringS3Output{}
					if f7f1iter.S3Output.LocalPath != nil {
						f7f1elemf0.LocalPath = f7f1iter.S3Output.LocalPath
					}
					if f7f1iter.S3Output.S3UploadMode != "" {
						f7f1elemf0.S3UploadMode = aws.String(string(f7f1iter.S3Output.S3UploadMode))
					}
					if f7f1iter.S3Output.S3Uri != nil {
						f7f1elemf0.S3URI = f7f1iter.S3Output.S3Uri
					}
					f7f1elem.S3Output = f7f1elemf0
				}
				f7f1 = append(f7f1, f7f1elem)
			}
			f7.MonitoringOutputs = f7f1
		}
		ko.Spec.ModelExplainabilityJobOutputConfig = f7
	} else {
		ko.Spec.ModelExplainabilityJobOutputConfig = nil
	}
	if resp.NetworkConfig != nil {
		f8 := &svcapitypes.MonitoringNetworkConfig{}
		if resp.NetworkConfig.EnableInterContainerTrafficEncryption != nil {
			f8.EnableInterContainerTrafficEncryption = resp.NetworkConfig.EnableInterContainerTrafficEncryption
		}
		if resp.NetworkConfig.EnableNetworkIsolation != nil {
			f8.EnableNetworkIsolation = resp.NetworkConfig.EnableNetworkIsolation
		}
		if resp.NetworkConfig.VpcConfig != nil {
			f8f2 := &svcapitypes.VPCConfig{}
			if resp.NetworkConfig.VpcConfig.SecurityGroupIds != nil {
				f8f2.SecurityGroupIDs = aws.StringSlice(resp.NetworkConfig.VpcConfig.SecurityGroupIds)
			}
			if resp.NetworkConfig.VpcConfig.Subnets != nil {
				f8f2.Subnets = aws.StringSlice(resp.NetworkConfig.VpcConfig.Subnets)
			}
			f8.VPCConfig = f8f2
		}
		ko.Spec.NetworkConfig = f8
	} else {
		ko.Spec.NetworkConfig = nil
	}
	if resp.RoleArn != nil {
		ko.Spec.RoleARN = resp.RoleArn
	} else {
		ko.Spec.RoleARN = nil
	}
	if resp.StoppingCondition != nil {
		f10 := &svcapitypes.MonitoringStoppingCondition{}
		if resp.StoppingCondition.MaxRuntimeInSeconds != nil {
			maxRuntimeInSecondsCopy := int64(*resp.StoppingCondition.MaxRuntimeInSeconds)
			f10.MaxRuntimeInSeconds = &maxRuntimeInSecondsCopy
		}
		ko.Spec.StoppingCondition = f10
	} else {
		ko.Spec.StoppingCondition = nil
	}

	rm.setStatusDefaults(ko)
	return &resource{ko}, nil
}

// requiredFieldsMissingFromReadOneInput returns true if there are any fields
// for the ReadOne Input shape that are required but not present in the
// resource's Spec or Status
func (rm *resourceManager) requiredFieldsMissingFromReadOneInput(
	r *resource,
) bool {
	return r.ko.Spec.JobDefinitionName == nil

}

// newDescribeRequestPayload returns SDK-specific struct for the HTTP request
// payload of the Describe API call for the resource
func (rm *resourceManager) newDescribeRequestPayload(
	r *resource,
) (*svcsdk.DescribeModelExplainabilityJobDefinitionInput, error) {
	res := &svcsdk.DescribeModelExplainabilityJobDefinitionInput{}

	if r.ko.Spec.JobDefinitionName != nil {
		res.JobDefinitionName = r.ko.Spec.JobDefinitionName
	}

	return res, nil
}

// sdkCreate creates the supplied resource in the backend AWS service API and
// returns a copy of the resource with resource fields (in both Spec and
// Status) filled in with values from the CREATE API operation's Output shape.
func (rm *resourceManager) sdkCreate(
	ctx context.Context,
	desired *resource,
) (created *resource, err error) {
	rlog := ackrtlog.FromContext(ctx)
	exit := rlog.Trace("rm.sdkCreate")
	defer func() {
		exit(err)
	}()
	input, err := rm.newCreateRequestPayload(ctx, desired)
	if err != nil {
		return nil, err
	}

	var resp *svcsdk.CreateModelExplainabilityJobDefinitionOutput
	_ = resp
	resp, err = rm.sdkapi.CreateModelExplainabilityJobDefinition(ctx, input)
	rm.metrics.RecordAPICall("CREATE", "CreateModelExplainabilityJobDefinition", err)
	if err != nil {
		return nil, err
	}
	// Merge in the information we read from the API call above to the copy of
	// the original Kubernetes object we passed to the function
	ko := desired.ko.DeepCopy()

	if ko.Status.ACKResourceMetadata == nil {
		ko.Status.ACKResourceMetadata = &ackv1alpha1.ResourceMetadata{}
	}
	if resp.JobDefinitionArn != nil {
		arn := ackv1alpha1.AWSResourceName(*resp.JobDefinitionArn)
		ko.Status.ACKResourceMetadata.ARN = &arn
	}

	rm.setStatusDefaults(ko)
	return &resource{ko}, nil
}

// newCreateRequestPayload returns an SDK-specific struct for the HTTP request
// payload of the Create API call for the resource
func (rm *resourceManager) newCreateRequestPayload(
	ctx context.Context,
	r *resource,
) (*svcsdk.CreateModelExplainabilityJobDefinitionInput, error) {
	res := &svcsdk.CreateModelExplainabilityJobDefinitionInput{}

	if r.ko.Spec.JobDefinitionName != nil {
		res.JobDefinitionName = r.ko.Spec.JobDefinitionName
	}
	if r.ko.Spec.JobResources != nil {
		f1 := &svcsdktypes.MonitoringResources{}
		if r.ko.Spec.JobResources.ClusterConfig != nil {
			f1f0 := &svcsdktypes.MonitoringClusterConfig{}
			if r.ko.Spec.JobResources.ClusterConfig.InstanceCount != nil {
				instanceCountCopy0 := *r.ko.Spec.JobResources.ClusterConfig.InstanceCount
				if instanceCountCopy0 > math.MaxInt32 || instanceCountCopy0 < math.MinInt32 {
					return nil, fmt.Errorf("error: field InstanceCount is of type int32")
				}
				instanceCountCopy := int32(instanceCountCopy0)
				f1f0.InstanceCount = &instanceCountCopy
			}
			if r.ko.Spec.JobResources.ClusterConfig.InstanceType != nil {
				f1f0.InstanceType = svcsdktypes.ProcessingInstanceType(*r.ko.Spec.JobResources.ClusterConfig.InstanceType)
			}
			if r.ko.Spec.JobResources.ClusterConfig.VolumeKMSKeyID != nil {
				f1f0.VolumeKmsKeyId = r.ko.Spec.JobResources.ClusterConfig.VolumeKMSKeyID
			}
			if r.ko.Spec.JobResources.ClusterConfig.VolumeSizeInGB != nil {
				volumeSizeInGBCopy0 := *r.ko.Spec.JobResources.ClusterConfig.VolumeSizeInGB
				if volumeSizeInGBCopy0 > math.MaxInt32 || volumeSizeInGBCopy0 < math.MinInt32 {
					return nil, fmt.Errorf("error: field VolumeSizeInGB is of type int32")
				}
				volumeSizeInGBCopy := int32(volumeSizeInGBCopy0)
				f1f0.VolumeSizeInGB = &volumeSizeInGBCopy
			}
			f1.ClusterConfig = f1f0
		}
		res.JobResources = f1
	}
	if r.ko.Spec.ModelExplainabilityAppSpecification != nil {
		f2 := &svcsdktypes.ModelExplainabilityAppSpecification{}
		if r.ko.Spec.ModelExplainabilityAppSpecification.ConfigURI != nil {
			f2.ConfigUri = r.ko.Spec.ModelExplainabilityAppSpecification.ConfigURI
		}
		if r.ko.Spec.ModelExplainabilityAppSpecification.Environment != nil {
			f2.Environment = aws.ToStringMap(r.ko.Spec.ModelExplainabilityAppSpecification.Environment)
		}
		if r.ko.Spec.ModelExplainabilityAppSpecification.ImageURI != nil {
			f2.ImageUri = r.ko.Spec.ModelExplainabilityAppSpecification.ImageURI
		}
		res.ModelExplainabilityAppSpecification = f2
	}
	if r.ko.Spec.ModelExplainabilityBaselineConfig != nil {
		f3 := &svcsdktypes.ModelExplainabilityBaselineConfig{}
		if r.ko.Spec.ModelExplainabilityBaselineConfig.BaseliningJobName != nil {
			f3.BaseliningJobName = r.ko.Spec.ModelExplainabilityBaselineConfig.BaseliningJobName
		}
		if r.ko.Spec.ModelExplainabilityBaselineConfig.ConstraintsResource != nil {
			f3f1 := &svcsdktypes.MonitoringConstraintsResource{}
			if r.ko.Spec.ModelExplainabilityBaselineConfig.ConstraintsResource.S3URI != nil {
				f3f1.S3Uri = r.ko.Spec.ModelExplainabilityBaselineConfig.ConstraintsResource.S3URI
			}
			f3.ConstraintsResource = f3f1
		}
		res.ModelExplainabilityBaselineConfig = f3
	}
	if r.ko.Spec.ModelExplainabilityJobInput != nil {
		f4 := &svcsdktypes.ModelExplainabilityJobInput{}
		if r.ko.Spec.ModelExplainabilityJobInput.EndpointInput != nil {
			f4f0 := &svcsdktypes.EndpointInput{}
			if r.ko.Spec.ModelExplainabilityJobInput.EndpointInput.EndTimeOffset != nil {
				f4f0.EndTimeOffset = r.ko.Spec.ModelExplainabilityJobInput.EndpointInput.EndTimeOffset
			}
			if r.ko.Spec.ModelExplainabilityJobInput.EndpointInput.EndpointName != nil {
				f4f0.EndpointName = r.ko.Spec.ModelExplainabilityJobInput.EndpointInput.EndpointName
			}
			if r.ko.Spec.ModelExplainabilityJobInput.EndpointInput.ExcludeFeaturesAttribute != nil {
				f4f0.ExcludeFeaturesAttribute = r.ko.Spec.ModelExplainabilityJobInput.EndpointInput.ExcludeFeaturesAttribute
			}
			if r.ko.Spec.ModelExplainabilityJobInput.EndpointInput.FeaturesAttribute != nil {
				f4f0.FeaturesAttribute = r.ko.Spec.ModelExplainabilityJobInput.EndpointInput.FeaturesAttribute
			}
			if r.ko.Spec.ModelExplainabilityJobInput.EndpointInput.InferenceAttribute != nil {
				f4f0.InferenceAttribute = r.ko.Spec.ModelExplainabilityJobInput.EndpointInput.InferenceAttribute
			}
			if r.ko.Spec.ModelExplainabilityJobInput.EndpointInput.LocalPath != nil {
				f4f0.LocalPath = r.ko.Spec.ModelExplainabilityJobInput.EndpointInput.LocalPath
			}
			if r.ko.Spec.ModelExplainabilityJobInput.EndpointInput.ProbabilityAttribute != nil {
				f4f0.ProbabilityAttribute = r.ko.Spec.ModelExplainabilityJobInput.EndpointInput.ProbabilityAttribute
			}
			if r.ko.Spec.ModelExplainabilityJobInput.EndpointInput.ProbabilityThresholdAttribute != nil {
				f4f0.ProbabilityThresholdAttribute = r.ko.Spec.ModelExplainabilityJobInput.EndpointInput.ProbabilityThresholdAttribute
			}
			if r.ko.Spec.ModelExplainabilityJobInput.EndpointInput.S3DataDistributionType != nil {
				f4f0.S3DataDistributionType = svcsdktypes.ProcessingS3DataDistributionType(*r.ko.Spec.ModelExplainabilityJobInput.EndpointInput.S3DataDistributionType)
			}
			if r.ko.Spec.ModelExplainabilityJobInput.EndpointInput.S3InputMode != nil {
				f4f0.S3InputMode = svcsdktypes.ProcessingS3InputMode(*r.ko.Spec.ModelExplainabilityJobInput.EndpointInput.S3InputMode)
			}
			if r.ko.Spec.ModelExplainabilityJobInput.EndpointInput.StartTimeOffset != nil {
				f4f0.StartTimeOffset = r.ko.Spec.ModelExplainabilityJobInput.EndpointInput.StartTimeOffset
			}
			f4.EndpointInput = f4f0
		}
		res.ModelExplainabilityJobInput = f4
	}
	if r.ko.Spec.ModelExplainabilityJobOutputConfig != nil {
		f5 := &svcsdktypes.MonitoringOutputConfig{}
		if r.ko.Spec.ModelExplainabilityJobOutputConfig.KMSKeyID != nil {
			f5.KmsKeyId = r.ko.Spec.ModelExplainabilityJobOutputConfig.KMSKeyID
		}
		if r.ko.Spec.ModelExplainabilityJobOutputConfig.MonitoringOutputs != nil {
			f5f1 := []svcsdktypes.MonitoringOutput{}
			for _, f5f1iter := range r.ko.Spec.ModelExplainabilityJobOutputConfig.MonitoringOutputs {
				f5f1elem := &svcsdktypes.MonitoringOutput{}
				if f5f1iter.S3Output != nil {
					f5f1elemf0 := &svcsdktypes.MonitoringS3Output{}
					if f5f1iter.S3Output.LocalPath != nil {
						f5f1elemf0.LocalPath = f5f1iter.S3Output.LocalPath
					}
					if f5f1iter.S3Output.S3UploadMode != nil {
						f5f1elemf0.S3UploadMode = svcsdktypes.ProcessingS3UploadMode(*f5f1iter.S3Output.S3UploadMode)
					}
					if f5f1iter.S3Output.S3URI != nil {
						f5f1elemf0.S3Uri = f5f1iter.S3Output.S3URI
					}
					f5f1elem.S3Output = f5f1elemf0
				}
				f5f1 = append(f5f1, *f5f1elem)
			}
			f5.MonitoringOutputs = f5f1
		}
		res.ModelExplainabilityJobOutputConfig = f5
	}
	if r.ko.Spec.NetworkConfig != nil {
		f6 := &svcsdktypes.MonitoringNetworkConfig{}
		if r.ko.Spec.NetworkConfig.EnableInterContainerTrafficEncryption != nil {
			f6.EnableInterContainerTrafficEncryption = r.ko.Spec.NetworkConfig.EnableInterContainerTrafficEncryption
		}
		if r.ko.Spec.NetworkConfig.EnableNetworkIsolation != nil {
			f6.EnableNetworkIsolation = r.ko.Spec.NetworkConfig.EnableNetworkIsolation
		}
		if r.ko.Spec.NetworkConfig.VPCConfig != nil {
			f6f2 := &svcsdktypes.VpcConfig{}
			if r.ko.Spec.NetworkConfig.VPCConfig.SecurityGroupIDs != nil {
				f6f2.SecurityGroupIds = aws.ToStringSlice(r.ko.Spec.NetworkConfig.VPCConfig.SecurityGroupIDs)
			}
			if r.ko.Spec.NetworkConfig.VPCConfig.Subnets != nil {
				f6f2.Subnets = aws.ToStringSlice(r.ko.Spec.NetworkConfig.VPCConfig.Subnets)
			}
			f6.VpcConfig = f6f2
		}
		res.NetworkConfig = f6
	}
	if r.ko.Spec.RoleARN != nil {
		res.RoleArn = r.ko.Spec.RoleARN
	}
	if r.ko.Spec.StoppingCondition != nil {
		f8 := &svcsdktypes.MonitoringStoppingCondition{}
		if r.ko.Spec.StoppingCondition.MaxRuntimeInSeconds != nil {
			maxRuntimeInSecondsCopy0 := *r.ko.Spec.StoppingCondition.MaxRuntimeInSeconds
			if maxRuntimeInSecondsCopy0 > math.MaxInt32 || maxRuntimeInSecondsCopy0 < math.MinInt32 {
				return nil, fmt.Errorf("error: field MaxRuntimeInSeconds is of type int32")
			}
			maxRuntimeInSecondsCopy := int32(maxRuntimeInSecondsCopy0)
			f8.MaxRuntimeInSeconds = &maxRuntimeInSecondsCopy
		}
		res.StoppingCondition = f8
	}
	if r.ko.Spec.Tags != nil {
		f9 := []svcsdktypes.Tag{}
		for _, f9iter := range r.ko.Spec.Tags {
			f9elem := &svcsdktypes.Tag{}
			if f9iter.Key != nil {
				f9elem.Key = f9iter.Key
			}
			if f9iter.Value != nil {
				f9elem.Value = f9iter.Value
			}
			f9 = append(f9, *f9elem)
		}
		res.Tags = f9
	}

	return res, nil
}

// sdkUpdate patches the supplied resource in the backend AWS service API and
// returns a new resource with updated fields.
func (rm *resourceManager) sdkUpdate(
	ctx context.Context,
	desired *resource,
	latest *resource,
	delta *ackcompare.Delta,
) (*resource, error) {
	return nil, ackerr.NewTerminalError(ackerr.NotImplemented)
}

// sdkDelete deletes the supplied resource in the backend AWS service API
func (rm *resourceManager) sdkDelete(
	ctx context.Context,
	r *resource,
) (latest *resource, err error) {
	rlog := ackrtlog.FromContext(ctx)
	exit := rlog.Trace("rm.sdkDelete")
	defer func() {
		exit(err)
	}()
	input, err := rm.newDeleteRequestPayload(r)
	if err != nil {
		return nil, err
	}
	var resp *svcsdk.DeleteModelExplainabilityJobDefinitionOutput
	_ = resp
	resp, err = rm.sdkapi.DeleteModelExplainabilityJobDefinition(ctx, input)
	rm.metrics.RecordAPICall("DELETE", "DeleteModelExplainabilityJobDefinition", err)
	return nil, err
}

// newDeleteRequestPayload returns an SDK-specific struct for the HTTP request
// payload of the Delete API call for the resource
func (rm *resourceManager) newDeleteRequestPayload(
	r *resource,
) (*svcsdk.DeleteModelExplainabilityJobDefinitionInput, error) {
	res := &svcsdk.DeleteModelExplainabilityJobDefinitionInput{}

	if r.ko.Spec.JobDefinitionName != nil {
		res.JobDefinitionName = r.ko.Spec.JobDefinitionName
	}

	return res, nil
}

// setStatusDefaults sets default properties into supplied custom resource
func (rm *resourceManager) setStatusDefaults(
	ko *svcapitypes.ModelExplainabilityJobDefinition,
) {
	if ko.Status.ACKResourceMetadata == nil {
		ko.Status.ACKResourceMetadata = &ackv1alpha1.ResourceMetadata{}
	}
	if ko.Status.ACKResourceMetadata.Region == nil {
		ko.Status.ACKResourceMetadata.Region = &rm.awsRegion
	}
	if ko.Status.ACKResourceMetadata.OwnerAccountID == nil {
		ko.Status.ACKResourceMetadata.OwnerAccountID = &rm.awsAccountID
	}
	if ko.Status.Conditions == nil {
		ko.Status.Conditions = []*ackv1alpha1.Condition{}
	}
}

// updateConditions returns updated resource, true; if conditions were updated
// else it returns nil, false
func (rm *resourceManager) updateConditions(
	r *resource,
	onSuccess bool,
	err error,
) (*resource, bool) {
	ko := r.ko.DeepCopy()
	rm.setStatusDefaults(ko)

	// Terminal condition
	var terminalCondition *ackv1alpha1.Condition = nil
	var recoverableCondition *ackv1alpha1.Condition = nil
	var syncCondition *ackv1alpha1.Condition = nil
	for _, condition := range ko.Status.Conditions {
		if condition.Type == ackv1alpha1.ConditionTypeTerminal {
			terminalCondition = condition
		}
		if condition.Type == ackv1alpha1.ConditionTypeRecoverable {
			recoverableCondition = condition
		}
		if condition.Type == ackv1alpha1.ConditionTypeResourceSynced {
			syncCondition = condition
		}
	}
	var termError *ackerr.TerminalError
	if rm.terminalAWSError(err) || err == ackerr.SecretTypeNotSupported || err == ackerr.SecretNotFound || errors.As(err, &termError) {
		if terminalCondition == nil {
			terminalCondition = &ackv1alpha1.Condition{
				Type: ackv1alpha1.ConditionTypeTerminal,
			}
			ko.Status.Conditions = append(ko.Status.Conditions, terminalCondition)
		}
		var errorMessage = ""
		if err == ackerr.SecretTypeNotSupported || err == ackerr.SecretNotFound || errors.As(err, &termError) {
			errorMessage = err.Error()
		} else {
			awsErr, _ := ackerr.AWSError(err)
			errorMessage = awsErr.Error()
		}
		terminalCondition.Status = corev1.ConditionTrue
		terminalCondition.Message = &errorMessage
	} else {
		// Clear the terminal condition if no longer present
		if terminalCondition != nil {
			terminalCondition.Status = corev1.ConditionFalse
			terminalCondition.Message = nil
		}
		// Handling Recoverable Conditions
		if err != nil {
			if recoverableCondition == nil {
				// Add a new Condition containing a non-terminal error
				recoverableCondition = &ackv1alpha1.Condition{
					Type: ackv1alpha1.ConditionTypeRecoverable,
				}
				ko.Status.Conditions = append(ko.Status.Conditions, recoverableCondition)
			}
			recoverableCondition.Status = corev1.ConditionTrue
			awsErr, _ := ackerr.AWSError(err)
			errorMessage := err.Error()
			if awsErr != nil {
				errorMessage = awsErr.Error()
			}
			recoverableCondition.Message = &errorMessage
		} else if recoverableCondition != nil {
			recoverableCondition.Status = corev1.ConditionFalse
			recoverableCondition.Message = nil
		}
	}
	// Required to avoid the "declared but not used" error in the default case
	_ = syncCondition
	if terminalCondition != nil || recoverableCondition != nil || syncCondition != nil {
		return &resource{ko}, true // updated
	}
	return nil, false // not updated
}

// terminalAWSError returns awserr, true; if the supplied error is an aws Error type
// and if the exception indicates that it is a Terminal exception
// 'Terminal' exception are specified in generator configuration
func (rm *resourceManager) terminalAWSError(err error) bool {
	if err == nil {
		return false
	}

	var terminalErr smithy.APIError
	if !errors.As(err, &terminalErr) {
		return false
	}
	switch terminalErr.ErrorCode() {
	case "ResourceNotFound",
		"ResourceInUse",
		"InvalidParameterCombination",
		"InvalidParameterValue",
		"MissingParameter":
		return true
	default:
		return false
	}
}
